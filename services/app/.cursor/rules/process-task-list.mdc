---
description: 
globs: 
alwaysApply: false
---
# Adaptive Task List Processing

## Token Limit: ~1000 lines maximum

Comprehensive guidelines for intelligently processing task lists in markdown files, with automatic adaptation based on task complexity and risk level.

## ðŸš¨ CRITICAL: Follow Claude 4 Best Practices (claude-4-best-practices.mdc)

**BEFORE STARTING ANY TASK:**
1. **Reflective iteration** - After user feedback, pause and determine optimal next steps
2. **Maximum effort** - Don't hold back, give comprehensive solutions  
3. **General-purpose solutions** - Work for all valid inputs, not just test cases

**MANDATORY PROTOCOLS:**
- **Use `poetry run python` for ALL commands** (pytest, mypy, ruff, black, etc.)
- **STOP and ask user to proceed** after completing each task or phase
- **Present initial assessment** and wait for "proceed" confirmation before starting

## Core Philosophy

1. **Understand before executing** - Analyze the entire task list to determine the appropriate approach
2. **Adapt to complexity** - Simple tasks get streamlined execution, complex tasks get careful treatment
3. **Respect warnings** - Critical markers and prerequisites are non-negotiable
4. **Continuous validation** - Test early, test often, especially for high-risk operations

## Initial Task Assessment

### When Starting a Task List

1. **Detect task structure type**:
   - Single file: `tasks-[feature-name].md` (legacy format)
   - Folder structure: `/tasks/[feature-name]/` with guide.md and phase files

2. **For folder structure**, read and analyze:
   - `guide.md` - Overall architecture, dependencies, patterns
   - All phase files - Individual phase tasks and dependencies
   - Phase metadata - Complexity, risk levels, time estimates

3. **For single file**, read and analyze:
   - Task type and complexity
   - Phase structure and dependencies
   - Risk indicators (CRITICAL, WARNING, MANDATORY markers)
   - Testing requirements
   - Success criteria

4. **Present initial assessment to user**:

```markdown
I've analyzed the task structure. Here's my understanding:

**Task Structure:**
- Format: [single file/folder with guide.md + N phase files]
- Feature: [feature-name]
- Complexity: [low/medium/high based on guide.md or task analysis]
- Risk level: [low/medium/high]
- Total estimated time: [from guide.md or calculated]

**Phase Structure:**
- Phase 0: [prerequisites if exists] - [estimated time]
- Phase 1: [foundation work] - [estimated time]  
- Phase 2: [core implementation] - [estimated time]
- Phase 3: [integration/polish] - [estimated time]

**Execution approach:**
[Brief description of how you'll proceed based on complexity and structure]

**Key Dependencies:**
- [From guide.md dependency graph]

**Validation strategy:**
- [Phase-specific validation requirements]

Ready to proceed with this approach? Type 'proceed' or let me know if I should adjust.
```

3. **Wait for user confirmation** before beginning execution

## Execution Modes

Based on the initial assessment, apply the appropriate execution mode:

### Mode 1: Streamlined (Low Risk/Simple Tasks)

**Indicators:**
- No critical warnings
- Single phase or simple task list
- Low risk of side effects
- Clear, straightforward requirements

**Approach:**
- Execute sub-tasks sequentially
- Quick validation after each task
- Minimal user interruption
- Batch status updates for related tasks

**Protocol:**
1. Complete sub-task
2. Run basic validation
3. Mark complete `[x]`
4. Continue to next sub-task
5. Report completion of task groups

### Mode 2: Standard (Medium Complexity)

**Indicators:**
- Multiple phases without strict prerequisites
- Moderate testing requirements
- Some integration points
- Standard refactoring or feature implementation

**Approach:**
- Phase-aware execution
- Test after implementation
- Regular checkpoints
- Standard validation at phase boundaries

**Protocol:**
1. Complete phase tasks
2. Run specified tests
3. Validate phase success criteria
4. Get approval before next phase
5. Document any discoveries

### Mode 3: Careful (High Risk/Complex)

**Indicators:**
- CRITICAL/WARNING markers
- Mandatory prerequisites (Phase 0)
- Database or API changes
- Performance-critical operations
- Complex refactoring

**Approach:**
- Strict phase enforcement
- Comprehensive testing first
- Detailed validation at each step
- Explicit approval for each sub-task
- Rollback preparation

**Protocol:**
1. **Never skip prerequisites**
2. Complete ALL Phase 0 tasks first
3. Achieve required test coverage
4. Get approval before EACH sub-task
5. Run full test suite after EACH change
6. Document everything

### Mode 4: Ultra-Careful (Critical Operations)

**Indicators:**
- Multiple CRITICAL warnings
- "NO TESTING = NO [ACTION]" requirements
- Core system modifications
- Security-sensitive changes
- Data migrations

**Approach:**
- Maximum validation
- Backup/rollback ready
- Performance baselines
- Step-by-step user confirmation
- Comprehensive documentation

**Protocol:**
1. Create full backup plan
2. Establish performance baselines
3. Create comprehensive test suite
4. Mock all external dependencies
5. Execute with extreme caution
6. Validate after every micro-change

## Task Execution Protocol

### Before Starting Any Sub-task

1. **Check current position** in task list
2. **Read task requirements** including any notes or warnings
3. **Assess task risk** based on what it modifies
4. **For non-trivial tasks**, outline approach:
   ```
   About to: [task description]
   Approach: [how you'll implement it]
   Files affected: [list]
   Validation: [how you'll verify success]
   ```
5. **Get appropriate approval**:
   - Streamlined mode: Proceed unless high-risk
   - Standard mode: Brief confirmation
   - Careful mode: Detailed approval
   - Ultra-careful mode: Step-by-step confirmation

### During Execution

1. **Follow task specifications exactly**
2. **Run validation commands** as specified
3. **Monitor for unexpected behavior**
4. **Document issues immediately**
5. **Stop if anything seems wrong**

### After Completing Sub-task

1. **Run specified validation**:
   - Tests (unit, integration, e2e as applicable)
   - Linting and formatting
   - Type checking
   - Performance benchmarks (if applicable)

2. **Update task status**:
   - Mark sub-task complete `[x]`
   - Update parent task if all sub-tasks done
   - Add any newly discovered tasks

3. **Report completion**:
   ```
   âœ“ Completed: [task description]
   Validation: [what passed]
   Changes: [brief summary]
   [Any issues or notes]

   Ready to proceed to next task? Please confirm.
   ```

4. **ðŸ›‘ MANDATORY: Wait for next instruction** - ALWAYS stop and ask user to proceed

## Special Protocols

### Testing-First Protocol

When encountering "NO TESTING = NO [ACTION]" or similar warnings:

1. **Stop everything** and focus on testing
2. **Create comprehensive test coverage**:
   - Unit tests for all functions/methods
   - Integration tests for interactions
   - Edge cases and error conditions
   - Performance benchmarks
3. **Achieve required coverage** (usually 95%+)
4. **Mock external dependencies**
5. **Document current behavior** through tests
6. **Only then** proceed to implementation

### Phase Checkpoint Protocol

At phase boundaries:

1. **Mark phase file tasks complete** with [x]
2. **Update folder structure status**:
   - Mark completed tasks in current phase file
   - Update guide.md if needed with discoveries
   - Prepare next phase file for execution
3. **Run phase validation suite** (from current phase file)
4. **Check phase completion criteria** (from current phase file)
5. **Generate phase summary**:
   ```
   Phase [X] Complete:
   - File: phase_[X].md
   - Tasks completed: [count] 
   - Tests passing: [status]
   - Coverage: [percentage]
   - Performance: [metrics]
   - Issues found: [list]
   - Newly discovered tasks: [count]
   Ready for Phase [X+1]? [yes/no]
   ```
6. **Get explicit approval** before continuing to next phase file

### Emergency Stop Protocol

Immediately stop and alert user if:
- Tests start failing after changes
- Unexpected behavior observed
- Requirements unclear
- Dependencies missing
- Performance degradation detected

Format:
```
ðŸ›‘ EMERGENCY STOP

Issue: [what went wrong]
When: [what you were doing]
Impact: [what might be affected]
Recommendation: [suggested action]

Please advise how to proceed.
```

## Task Structure Maintenance

### For Folder Structure

1. **Update phase files** in real-time:
   - Mark tasks complete with [x] immediately upon validation
   - Add new tasks with **NEW** marker to appropriate phase file
   - Update phase metadata if estimates change

2. **Update guide.md** when needed:
   - Add newly discovered files to relevant file sections
   - Update architecture diagrams if components change
   - Document blockers or risk changes

3. **Cross-phase consistency**:
   - Ensure task numbering remains consistent across phases
   - Update phase dependencies if new dependencies discovered
   - Maintain file path consistency across all phase files

### For Single File (Legacy)

1. **Mark tasks complete** immediately upon validation
2. **Add new tasks** as discovered with **NEW** marker
3. **Update file lists** with every change
4. **Document blockers** with clear descriptions

### Progress Tracking

Use TodoWrite/TodoRead tools to maintain a parallel tracking system for complex projects:
- Major milestones
- Current phase focus
- Cross-phase blockers
- Next phase preparations

### Relevant Files Section

Maintain in guide.md (folder structure) or task file (single file):
- Full path to each file
- One-line purpose description
- NEW/MODIFIED status
- Which phase(s) modify the file

## ðŸ”§ MANDATORY Command Execution Guidelines

### âš ï¸ CRITICAL: Always Use Poetry

**NEVER use bare commands like `pytest`, `mypy`, `ruff` - ALWAYS prefix with `poetry run python`**

### Testing Commands
```bash
# Unit tests - CORRECT
poetry run python pytest tests/unit -v

# With coverage - CORRECT  
poetry run python pytest --cov=src --cov-report=term-missing

# Specific test file - CORRECT
poetry run python pytest tests/unit/test_specific.py -v

# Integration tests - CORRECT
poetry run python pytest tests/integration -v

# Performance tests - CORRECT
poetry run python pytest tests/performance -v --benchmark-only

# WRONG - DO NOT USE:
# pytest tests/unit -v  âŒ
# mypy src/  âŒ  
# ruff check .  âŒ
```

### Validation Commands
```bash
# Type checking - ALWAYS use poetry run python
poetry run python mypy src/

# Linting - ALWAYS use poetry run python
poetry run python ruff check .
poetry run python flake8

# Formatting - ALWAYS use poetry run python
poetry run python black . --check
poetry run python isort . --check

# Security - ALWAYS use poetry run python
poetry run python bandit -r src/

# WRONG - DO NOT USE bare commands:
# mypy src/  âŒ
# ruff check .  âŒ
# black . --check  âŒ
```

### Git Operations
```bash
# Always check status first
git status

# Create feature branch
git checkout -b feature/task-name

# Commit with message
git add -A
git commit -m "feat: implement [description]"

# Keep commits atomic and focused
```

## Decision Tree for Task Execution

```
Start
  â”‚
  â”œâ”€> Detect structure type
  â”‚   â”œâ”€> Folder structure: Read guide.md + all phase files
  â”‚   â””â”€> Single file: Read task file
  â”‚
  â”œâ”€> Analyze complexity indicators
  â”‚   â”œâ”€> Folder structure: Check guide.md metadata + phase risk levels
  â”‚   â””â”€> Single file: Check CRITICAL/WARNING markers
  â”‚
  â”œâ”€> Contains CRITICAL/WARNING markers OR high risk phases?
  â”‚   â”œâ”€> Yes: Use Careful or Ultra-Careful mode
  â”‚   â””â”€> No: Continue assessment
  â”‚
  â”œâ”€> Has Phase 0 or mandatory prerequisites?
  â”‚   â”œâ”€> Yes: Use Careful mode minimum
  â”‚   â””â”€> No: Continue assessment
  â”‚
  â”œâ”€> Multiple phases with complex dependencies?
  â”‚   â”œâ”€> Yes: Use Standard or Careful mode
  â”‚   â””â”€> No: Continue assessment
  â”‚
  â”œâ”€> Simple phase structure, low risk?
  â”‚   â”œâ”€> Yes: Use Streamlined mode
  â”‚   â””â”€> No: Use Standard mode
  â”‚
  â””â”€> Begin execution in selected mode
```

## Best Practices

### Core Principles (see claude-4-best-practices.mdc)
1. **Reflective iteration** - After feedback, pause and determine optimal next steps
2. **Maximum effort** - Don't hold back, give comprehensive solutions
3. **General-purpose solutions** - Work for all valid inputs, not just test cases

### Task-Specific Practices
1. **Err on the side of caution** - When unsure, use a more careful mode
2. **Validate assumptions** - Test your understanding before making changes
3. **Communicate clearly** - Explain what you're doing and why
4. **Maintain momentum** - Balance caution with progress
5. **Learn from the task list** - Complex lists often embed domain knowledge

### After User Feedback
**CRITICAL**: Before implementing feedback, always:
```
User feedback received. Reflecting on this:
- What they're really asking for: [deeper insight]
- Why this feedback matters: [reasoning]
- How this changes my approach: [adjustments]
- Optimal next steps: [refined plan]
```

## Examples of Mode Selection

### Example 1: Simple Feature Addition (Folder Structure)
```
/tasks/add-dashboard-button/
â”œâ”€â”€ guide.md (complexity: low, risk: low)
â”œâ”€â”€ phase_1.md (implementation)
â””â”€â”€ phase_2.md (testing)
```
â†’ **Streamlined Mode**: Low complexity/risk in guide.md, simple phase structure

### Example 2: API Refactoring (Folder Structure)
```
/tasks/api-refactoring/
â”œâ”€â”€ guide.md (complexity: high, risk: medium, compatibility warnings)
â”œâ”€â”€ phase_0.md (prerequisites: comprehensive testing)
â”œâ”€â”€ phase_1.md (refactoring)
â””â”€â”€ phase_2.md (validation)
```
â†’ **Careful Mode**: Phase 0 exists, compatibility requirements in guide.md

### Example 3: Critical System Update (Folder Structure)
```
/tasks/database-migration/
â”œâ”€â”€ guide.md (ðŸš¨ CRITICAL warnings, risk: high)
â”œâ”€â”€ phase_0.md (mandatory prerequisites, NO TESTING = NO MIGRATION)
â”œâ”€â”€ phase_1.md (backup procedures)
â”œâ”€â”€ phase_2.md (migration execution)
â””â”€â”€ phase_3.md (validation & rollback ready)
```
â†’ **Ultra-Careful Mode**: Critical warnings in guide.md, mandatory phase 0

### Example 4: Legacy Single File
```markdown
# ðŸš¨ CRITICAL: Database Migration ðŸš¨
# NO TESTING = NO MIGRATION

Phase 0: Mandatory Prerequisites
- [ ] Full database backup
```
â†’ **Ultra-Careful Mode**: Critical warnings, database changes (same as before)

## Final Reminders

- The mode selection is adaptive - escalate if you discover complexity
- User safety and system stability always take precedence over speed
- When in doubt, ask for clarification
- Document everything for complex operations
- Test, test, test - especially for high-risk tasks