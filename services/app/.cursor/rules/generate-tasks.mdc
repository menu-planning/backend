---
description: 
globs: 
alwaysApply: false
---
# Rule: Adaptive Task List Generation from PRD

## Goal

Guide an AI assistant in creating a comprehensive, adaptive task list in Markdown format from a Product Requirements Document (PRD). The task list adapts its depth and approach based on feature complexity and user preferences, ensuring appropriate guidance for implementation.

## Output

- **Format:** Markdown (`.md`)
- **Location:** `/tasks/`
- **Filename:** `tasks-[prd-file-name].md` (e.g., `tasks-prd-user-profile-editing.md`)

## Process Overview

### Phase 1: Initial Assessment & Questions

When user requests task generation from a PRD:

1. **Read and analyze the PRD** for initial complexity indicators
2. **Ask clarifying questions** to determine appropriate approach
3. **Wait for user responses** before proceeding
4. **Generate adaptive task list** based on assessment

### Assessment Questions

Present these questions to the user:

```markdown
I've analyzed the PRD. To create the most helpful task list, I need to understand your preferences:

**1. Implementation Context**
- What type of work is this? (new feature/refactoring/enhancement/bug fix)
- Are you modifying existing code or creating new components?
- What's the current test coverage for affected areas?

**2. Task Detail Level**
- How detailed should subtasks be? (high-level guidance vs step-by-step instructions)
- Should I include code examples or implementation patterns?
- Do you prefer specific file paths or general component references?

**3. Technical Approach**
- What's your testing strategy? (TDD/test-after/specific frameworks)
- Are there specific architectural patterns to follow?
- Any performance or security constraints to consider?

**4. Risk & Complexity**
- What are the main technical risks or complexities?
- Are there critical dependencies between components?
- What could break if implemented incorrectly?

**Quick Options:**
- Type "standard" for balanced detail with common best practices
- Type "detailed" for comprehensive step-by-step guidance
- Type "minimal" for high-level tasks only
- Or answer the questions above for a customized approach
```

### Phase 2: Adaptive Generation

Based on user responses, apply appropriate generation strategy:

#### For High-Complexity/Risk Features (or "detailed" option):
- Include Phase 0 with mandatory prerequisites
- Comprehensive testing requirements
- Detailed subtasks with technical specifications
- Risk warnings and validation checkpoints
- Implementation patterns and examples
- Success criteria and metrics

#### For Standard Features (or "standard" option):
- Clear phase separation without mandatory prerequisites
- Balanced subtasks with key technical details
- Core testing requirements
- Essential validation points
- File organization guidance

#### For Simple Features (or "minimal" option):
- Concise parent tasks with minimal subtasks
- Focus on core functionality
- Basic testing checklist
- Key files to modify

### Phase 3: Interactive Refinement

After generating initial task structure:

1. **Present high-level phases** without detailed subtasks
2. **Message:** "I've generated the task structure based on your preferences. Here's the high-level breakdown. Ready to see detailed subtasks? Type 'Go' to proceed, or let me know what to adjust."
3. **Wait for confirmation or adjustments**
4. **Generate detailed subtasks** based on feedback

## Adaptive Task Structure

### High-Complexity Template

```markdown
# üö® CRITICAL: [MAIN WARNING IF APPLICABLE] üö®

[Critical warnings for high-risk refactoring or complex features]

# Task List: [Feature Name]

## Implementation Approach
[Brief description of chosen approach based on user input]

## Current Implementation References (if refactoring)
### Core Components
- [file path] - [current implementation details]
- [file path] - [patterns to observe]

## Relevant Files

### [Component Category]
- `path/to/file.ts` - [Description] (NEW/MODIFIED)
- `path/to/file.test.ts` - Unit tests for file.ts (NEW)

## Testing Strategy
- Unit Tests: [Approach and coverage target]
- Integration Tests: [Scope and approach]
- E2E Tests: [Critical paths if applicable]

---

# üìä Tasks

## Phase 0: Mandatory Prerequisites ‚ö†Ô∏è
**This phase is NON-NEGOTIABLE. Skipping guarantees failure.**

### 0.1 Comprehensive Analysis & Testing
- [ ] 0.1.1 [Specific analysis task]
- [ ] 0.1.2 [Testing current behavior]
- [ ] 0.1.3 [Document edge cases]

**üõë CHECKPOINT: Do not proceed until Phase 0 is complete üõë**

## Phase 1: Foundation
[Continue with detailed phases...]

## üéØ Success Criteria
1. [Measurable outcome]
2. [Quality metric]
```

### Standard Template

```markdown
# Task List: [Feature Name]

## Overview
[Brief description based on PRD and user preferences]

## Relevant Files
### Core Implementation
- `path/to/component.ts` - [Purpose]
- `path/to/component.test.ts` - Tests

### API/Backend
- `path/to/api/endpoint.ts` - [Purpose]

## Testing Notes
- Run tests with: `[command based on user input]`
- Focus on: [key testing areas]

---

# Tasks

## Phase 1: Core Implementation
### 1.0 [Major Component]
- [ ] 1.1 [Implementation task]
- [ ] 1.2 [Testing task]

## Phase 2: Integration
### 2.0 [Integration Work]
- [ ] 2.1 [Specific task]

## Final Validation
- [ ] All tests passing
- [ ] [Other validation criteria]
```

### Minimal Template

```markdown
# Task List: [Feature Name]

## Quick Summary
[One paragraph overview]

## Key Files
- `main/file/to/modify.ts`
- `test/file/to/update.test.ts`

## Tasks
- [ ] 1. [High-level task]
  - [ ] [Essential subtask if needed]
- [ ] 2. [Another high-level task]
- [ ] 3. Run tests and validate
```

## Smart Defaults

When user chooses "standard" or doesn't specify:

### Auto-Detection Rules
1. **Refactoring indicators** ‚Üí Use high-complexity template
   - Keywords: refactor, migrate, redesign, optimize
   - Multiple service modifications
   - Database schema changes

2. **New feature indicators** ‚Üí Use standard template
   - Keywords: add, implement, create new
   - Isolated component work
   - Clear boundaries

3. **Enhancement indicators** ‚Üí Use minimal template
   - Keywords: update, modify, enhance
   - Single component changes
   - Bug fixes

## Special Considerations

### For Test-Driven Development (TDD)
If user indicates TDD approach:
- Place test tasks before implementation tasks
- Include test-first reminders
- Add "Red-Green-Refactor" cycle notes

### For Performance-Critical Features
If performance is mentioned:
- Include performance baseline tasks
- Add measurement tasks after implementation
- Include optimization phase if needed

### For Security-Sensitive Features
If security/auth is involved:
- Add security review checkpoints
- Include penetration testing tasks
- Add audit logging requirements

## Task Numbering Guidelines

- Use consistent hierarchical numbering
- Allow gaps for insertion (use 0.1, 0.2 instead of 1, 2)
- Mark discovered tasks with **NEW**
- Keep phases clearly separated

## Quality Checks

Before finalizing:
1. Tasks align with user's stated preferences
2. Detail level matches requested approach
3. Testing strategy reflects user's methodology
4. File paths follow project conventions
5. Risk warnings included where appropriate

## Examples of Adaptive Responses

### Example 1: User chooses "detailed" for refactoring
‚Üí Full Phase 0 with comprehensive testing
‚Üí Detailed implementation patterns
‚Üí Multiple validation checkpoints

### Example 2: User chooses "minimal" for bug fix
‚Üí 3-5 concise tasks
‚Üí Focus on fix and validation
‚Üí No phases, just numbered tasks

### Example 3: User provides custom preferences
‚Üí Incorporate specific testing framework
‚Üí Follow stated architectural patterns
‚Üí Adjust detail level per request

## Best Practices Integration

### Core Principles (see claude-4-best-practices.mdc)
1. **Give it your all** - Create comprehensive, thoughtful task lists
2. **General-purpose approach** - Tasks should work for various team sizes and skill levels
3. **Reflective iteration** - After user feedback, refine the entire approach

### Task Generation Excellence
- **Comprehensive coverage** - Include testing, documentation, validation
- **Flexible detail levels** - Adapt to team needs and complexity
- **Future-proof structure** - Tasks should remain relevant as project evolves
- **Error-resistant planning** - Anticipate common pitfalls and include prevention

### After User Feedback on Generated Tasks
**ALWAYS** reflect before adjusting:
```
User feedback on task list. Reflecting:
- What they're really asking for: [insight into their needs]
- Why this matters: [impact on project success]
- Better task structure: [refined approach]
- Optimal adjustments: [specific improvements]
```

## Final Notes

- Always wait for user confirmation before generating detailed subtasks
- Be prepared to adjust based on feedback with thoughtful reflection
- Include discovered tasks as work progresses
- Maintain consistency with user's stated preferences throughout
- Strive for excellence in task planning - it determines project success